{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "713db098-ab25-4482-af01-60dfada508de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('/fs/ess/PGS0333/BA_64061_KSU/data/dogs-vs-cats.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/users/PGS0333/rishitha/AML_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6572d9d2-6cc3-4844-afca-190c4d0378f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/PGS0333/rishitha/osc_classes/BA_64061_KSU'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863a41e0-2408-4ab5-a5c0-f2cefed6067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/users/PGS0333/rishitha/AML_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b740937-2a69-4e5a-b702-d98aeab4d008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open dogs-vs-cats.zip, dogs-vs-cats.zip.zip or dogs-vs-cats.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "# Unzipping dogs-vs-cats dataset file\n",
    "!unzip -qq dogs-vs-cats.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd338c33-11ed-4b24-afc3-d857b6144b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Unzipping train sample \n",
    "!unzip -o -qq train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9146a3ad-1cb0-41be-92f8-0af5f6d91266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directories and assiging images to training, validation and test directories\n",
    "import os, shutil, pathlib\n",
    "\n",
    "shutil.rmtree(\"cats_vs_dogs_small\")\n",
    "\n",
    "original_dir = pathlib.Path(\"train\")\n",
    "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7b5b6b-d773-4e43-b7e6-d9dfe7456ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 178, 178, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 89, 89, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 87, 87, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 41, 41, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 12545     \n",
      "=================================================================\n",
      "Total params: 991,041\n",
      "Trainable params: 991,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building the model and running the model summary \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1ca23e-99e9-4d3b-9fb8-0bb69968ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration of the model\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "924dec9e-ebad-4e03-a473-ca5b64e1c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Declaring the image size and batch size to read the images from train. validation and test directories\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8be95e14-c3b9-41c3-8aec-000b33fc68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 88s 1s/step - loss: 0.7205 - accuracy: 0.5280 - val_loss: 0.6910 - val_accuracy: 0.5030\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.7094 - accuracy: 0.5415 - val_loss: 0.7159 - val_accuracy: 0.5010\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.7054 - accuracy: 0.5815 - val_loss: 0.6530 - val_accuracy: 0.5870\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.6762 - accuracy: 0.6175 - val_loss: 0.6683 - val_accuracy: 0.5610\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.6146 - accuracy: 0.6445 - val_loss: 0.6684 - val_accuracy: 0.6220\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.5890 - accuracy: 0.6995 - val_loss: 0.7382 - val_accuracy: 0.5980\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.5595 - accuracy: 0.7195 - val_loss: 0.6750 - val_accuracy: 0.6550\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.5135 - accuracy: 0.7570 - val_loss: 0.6285 - val_accuracy: 0.6750\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.4661 - accuracy: 0.7685 - val_loss: 0.7474 - val_accuracy: 0.6680\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.4112 - accuracy: 0.8095 - val_loss: 0.5626 - val_accuracy: 0.7350\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.3717 - accuracy: 0.8360 - val_loss: 0.8242 - val_accuracy: 0.6610\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.2995 - accuracy: 0.8670 - val_loss: 0.7379 - val_accuracy: 0.7290\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.2793 - accuracy: 0.8765 - val_loss: 0.7730 - val_accuracy: 0.7140\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.2180 - accuracy: 0.9120 - val_loss: 0.8313 - val_accuracy: 0.7210\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.1823 - accuracy: 0.9310 - val_loss: 0.8538 - val_accuracy: 0.7040\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.1386 - accuracy: 0.9475 - val_loss: 0.9368 - val_accuracy: 0.7220\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.1152 - accuracy: 0.9525 - val_loss: 1.3794 - val_accuracy: 0.7310\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.1177 - accuracy: 0.9640 - val_loss: 1.1809 - val_accuracy: 0.7080\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.0748 - accuracy: 0.9765 - val_loss: 2.8454 - val_accuracy: 0.6470\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.0959 - accuracy: 0.9695 - val_loss: 1.4650 - val_accuracy: 0.7070\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.0871 - accuracy: 0.9690 - val_loss: 1.8558 - val_accuracy: 0.6720\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.0568 - accuracy: 0.9780 - val_loss: 1.6374 - val_accuracy: 0.7280\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.0794 - accuracy: 0.9795 - val_loss: 1.7241 - val_accuracy: 0.7100\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 1.9182 - val_accuracy: 0.7140\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.0633 - accuracy: 0.9785 - val_loss: 1.9460 - val_accuracy: 0.7250\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.0537 - accuracy: 0.9840 - val_loss: 2.1606 - val_accuracy: 0.7210\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.0949 - accuracy: 0.9765 - val_loss: 2.1079 - val_accuracy: 0.7240\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.0389 - accuracy: 0.9880 - val_loss: 2.1998 - val_accuracy: 0.7240\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.0404 - accuracy: 0.9900 - val_loss: 2.4042 - val_accuracy: 0.7120\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.0407 - accuracy: 0.9855 - val_loss: 2.5279 - val_accuracy: 0.7270\n"
     ]
    }
   ],
   "source": [
    "# Using the callbacks function to monitor validation loss and running the model\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1524ed-218c-4af9-9e10-23af61f677df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 327ms/step - loss: 0.0967 - accuracy: 0.9630\n",
      "Test accuracy: 0.963\n"
     ]
    }
   ],
   "source": [
    "# Testing the model \n",
    "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9fc90bc-dad2-4eae-a437-db4f16a1e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring Data Augumentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3376f84f-89f2-4179-9172-b64d20297441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model and configuing it \n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92cd7971-31b4-4ce4-a271-ab3dde56f169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "63/63 [==============================] - 95s 1s/step - loss: 0.7252 - accuracy: 0.5245 - val_loss: 0.6923 - val_accuracy: 0.5310\n",
      "Epoch 2/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.7039 - accuracy: 0.5120 - val_loss: 0.6813 - val_accuracy: 0.5590\n",
      "Epoch 3/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.6948 - accuracy: 0.5435 - val_loss: 0.6783 - val_accuracy: 0.5960\n",
      "Epoch 4/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.6812 - accuracy: 0.5905 - val_loss: 0.6632 - val_accuracy: 0.6010\n",
      "Epoch 5/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.6575 - accuracy: 0.6220 - val_loss: 0.6427 - val_accuracy: 0.6370\n",
      "Epoch 6/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.6478 - accuracy: 0.6400 - val_loss: 0.7441 - val_accuracy: 0.5470\n",
      "Epoch 7/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.6387 - accuracy: 0.6510 - val_loss: 0.6171 - val_accuracy: 0.6560\n",
      "Epoch 8/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.6062 - accuracy: 0.6795 - val_loss: 0.6048 - val_accuracy: 0.6650\n",
      "Epoch 9/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.5974 - accuracy: 0.6920 - val_loss: 0.6623 - val_accuracy: 0.6280\n",
      "Epoch 10/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.5963 - accuracy: 0.6805 - val_loss: 0.6800 - val_accuracy: 0.6670\n",
      "Epoch 11/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.5753 - accuracy: 0.7170 - val_loss: 0.5621 - val_accuracy: 0.7030\n",
      "Epoch 12/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.5513 - accuracy: 0.7225 - val_loss: 0.5407 - val_accuracy: 0.7340\n",
      "Epoch 13/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.5428 - accuracy: 0.7400 - val_loss: 0.5068 - val_accuracy: 0.7610\n",
      "Epoch 14/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.5326 - accuracy: 0.7505 - val_loss: 0.5512 - val_accuracy: 0.7090\n",
      "Epoch 15/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.5321 - accuracy: 0.7330 - val_loss: 0.5159 - val_accuracy: 0.7540\n",
      "Epoch 16/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.5182 - accuracy: 0.7540 - val_loss: 0.5177 - val_accuracy: 0.7460\n",
      "Epoch 17/40\n",
      "63/63 [==============================] - 91s 1s/step - loss: 0.4955 - accuracy: 0.7725 - val_loss: 0.4897 - val_accuracy: 0.7620\n",
      "Epoch 18/40\n",
      "63/63 [==============================] - 91s 1s/step - loss: 0.4895 - accuracy: 0.7615 - val_loss: 0.4524 - val_accuracy: 0.7980\n",
      "Epoch 19/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.4824 - accuracy: 0.7695 - val_loss: 0.5085 - val_accuracy: 0.7620\n",
      "Epoch 20/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.4590 - accuracy: 0.7840 - val_loss: 0.5094 - val_accuracy: 0.7600\n",
      "Epoch 21/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.4797 - accuracy: 0.7805 - val_loss: 0.4794 - val_accuracy: 0.7690\n",
      "Epoch 22/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.4598 - accuracy: 0.7895 - val_loss: 0.5112 - val_accuracy: 0.7560\n",
      "Epoch 23/40\n",
      "63/63 [==============================] - 91s 1s/step - loss: 0.4580 - accuracy: 0.7890 - val_loss: 0.6995 - val_accuracy: 0.6570\n",
      "Epoch 24/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.4458 - accuracy: 0.7895 - val_loss: 0.5832 - val_accuracy: 0.7590\n",
      "Epoch 25/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.4258 - accuracy: 0.8120 - val_loss: 0.4637 - val_accuracy: 0.7990\n",
      "Epoch 26/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.4290 - accuracy: 0.7995 - val_loss: 0.4591 - val_accuracy: 0.8000\n",
      "Epoch 27/40\n",
      "63/63 [==============================] - 91s 1s/step - loss: 0.4391 - accuracy: 0.8070 - val_loss: 0.5104 - val_accuracy: 0.7780\n",
      "Epoch 28/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.4075 - accuracy: 0.8175 - val_loss: 0.4575 - val_accuracy: 0.7980\n",
      "Epoch 29/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.4039 - accuracy: 0.8250 - val_loss: 0.4543 - val_accuracy: 0.7900\n",
      "Epoch 30/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.3930 - accuracy: 0.8180 - val_loss: 0.4850 - val_accuracy: 0.7830\n",
      "Epoch 31/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.3858 - accuracy: 0.8320 - val_loss: 0.4314 - val_accuracy: 0.8120\n",
      "Epoch 32/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.3703 - accuracy: 0.8455 - val_loss: 0.5256 - val_accuracy: 0.7800\n",
      "Epoch 33/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.3768 - accuracy: 0.8325 - val_loss: 0.4266 - val_accuracy: 0.8110\n",
      "Epoch 34/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.3714 - accuracy: 0.8410 - val_loss: 0.4115 - val_accuracy: 0.8240\n",
      "Epoch 35/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.3745 - accuracy: 0.8400 - val_loss: 0.4232 - val_accuracy: 0.8160\n",
      "Epoch 36/40\n",
      "63/63 [==============================] - 91s 1s/step - loss: 0.3596 - accuracy: 0.8425 - val_loss: 0.4918 - val_accuracy: 0.8140\n",
      "Epoch 37/40\n",
      "63/63 [==============================] - 91s 1s/step - loss: 0.3588 - accuracy: 0.8515 - val_loss: 0.6210 - val_accuracy: 0.7520\n",
      "Epoch 38/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.3458 - accuracy: 0.8525 - val_loss: 0.4488 - val_accuracy: 0.8040\n",
      "Epoch 39/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.3330 - accuracy: 0.8565 - val_loss: 0.4823 - val_accuracy: 0.8100\n",
      "Epoch 40/40\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.3436 - accuracy: 0.8465 - val_loss: 0.4903 - val_accuracy: 0.8060\n"
     ]
    }
   ],
   "source": [
    "\n",
    "   # Using the callbacks function to monitor validation loss and running the model\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=40,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651a0652-3bc1-4d7c-a679-36a08c224eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 327ms/step - loss: 0.4701 - accuracy: 0.8045\n",
      "Test accuracy: 0.804\n"
     ]
    }
   ],
   "source": [
    "test_model = keras.models.load_model(\n",
    "    \"convnet_from_scratch_with_augmentation.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a21f187-fd0f-4097-b5d2-62f4995f8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directories and assiging images to training, validation and test directories\n",
    "# Increasing the training sample from 1000 to 2000\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "shutil.rmtree(\"cats_vs_dogs_small_IncreasedTrainSample\")\n",
    "original_dir = pathlib.Path(\"train\")\n",
    "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_IncreasedTrainSample\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
    "\n",
    "# Training has 2000 samples, test has 1000 samples, and validation has 500 samples\n",
    "make_subset(\"train\", start_index=0, end_index=2000)\n",
    "make_subset(\"validation\", start_index=2000, end_index=2500)\n",
    "make_subset(\"test\", start_index=2500, end_index=3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "811e0e5c-8a01-4d1e-a12d-e7a84eb884fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "399ec1d9-b5ad-408b-94d6-eedaa4dff28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the model \n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b77aea18-3651-49b6-93ad-568f6d0c3a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 88s 1s/step - loss: 0.7456 - accuracy: 0.5110 - val_loss: 0.6885 - val_accuracy: 0.5470\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.7061 - accuracy: 0.5625 - val_loss: 0.6680 - val_accuracy: 0.5950\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 87s 1s/step - loss: 0.6763 - accuracy: 0.5940 - val_loss: 0.6404 - val_accuracy: 0.6160\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.6404 - accuracy: 0.6445 - val_loss: 0.6009 - val_accuracy: 0.6810\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.6114 - accuracy: 0.6835 - val_loss: 0.6029 - val_accuracy: 0.6890\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.5697 - accuracy: 0.7105 - val_loss: 0.5398 - val_accuracy: 0.7200\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.5191 - accuracy: 0.7365 - val_loss: 0.8860 - val_accuracy: 0.6280\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.4796 - accuracy: 0.7845 - val_loss: 0.5647 - val_accuracy: 0.7180\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.4438 - accuracy: 0.8045 - val_loss: 0.5094 - val_accuracy: 0.7560\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 87s 1s/step - loss: 0.3558 - accuracy: 0.8410 - val_loss: 0.5962 - val_accuracy: 0.7260\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.2968 - accuracy: 0.8760 - val_loss: 0.6441 - val_accuracy: 0.7290\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.2540 - accuracy: 0.9025 - val_loss: 0.6683 - val_accuracy: 0.7260\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.1980 - accuracy: 0.9200 - val_loss: 0.6886 - val_accuracy: 0.7610\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.1607 - accuracy: 0.9370 - val_loss: 1.4423 - val_accuracy: 0.6920\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 87s 1s/step - loss: 0.1202 - accuracy: 0.9615 - val_loss: 0.8767 - val_accuracy: 0.7620\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 87s 1s/step - loss: 0.1088 - accuracy: 0.9640 - val_loss: 1.1386 - val_accuracy: 0.7430\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.0839 - accuracy: 0.9660 - val_loss: 1.0745 - val_accuracy: 0.7450\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.0686 - accuracy: 0.9740 - val_loss: 1.2091 - val_accuracy: 0.7570\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.0575 - accuracy: 0.9795 - val_loss: 1.3439 - val_accuracy: 0.7450\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.0687 - accuracy: 0.9785 - val_loss: 1.3134 - val_accuracy: 0.7350\n"
     ]
    }
   ],
   "source": [
    "# Using the callbacks function to monitor validation loss and running the model\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=20,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98032523-4346-4d70-b3fa-91d402f9fcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 331ms/step - loss: 0.0967 - accuracy: 0.9630\n",
      "Test accuracy: 0.963\n"
     ]
    }
   ],
   "source": [
    "# Testing the model \n",
    "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d61bcaf0-96fc-4018-968c-51d9de528119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directories and assiging images to training, validation and test directories\n",
    "# Increasing the training sample from 1000 to 2000\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "original_dir = pathlib.Path(\"train\")\n",
    "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_OptimalTrainSamples1\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir,exist_ok=True)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
    "\n",
    "# Training has 1500 samples, test has 1000 samples, and validation has 500 samples\n",
    "# make_subset(\"train\", start_index=0, end_index=3500)\n",
    "# make_subset(\"validation\", start_index=2500, end_index=3000)\n",
    "# make_subset(\"test\", start_index=3000, end_index=4000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce1fd57-3e19-40f0-85d2-0d45bfd61459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ca82bbd-79c5-4c5b-9ab4-c5ae0e8cd47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the model \n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b418415-ffa3-4bac-ac4f-2eecee36781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 files belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 175s 869ms/step - loss: 0.7034 - accuracy: 0.5362 - val_loss: 0.7061 - val_accuracy: 0.5180\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 170s 852ms/step - loss: 0.6654 - accuracy: 0.6070 - val_loss: 0.6170 - val_accuracy: 0.6560\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 170s 851ms/step - loss: 0.6156 - accuracy: 0.6622 - val_loss: 0.5946 - val_accuracy: 0.6810\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 170s 849ms/step - loss: 0.5899 - accuracy: 0.6883 - val_loss: 0.5980 - val_accuracy: 0.6820\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 170s 852ms/step - loss: 0.5477 - accuracy: 0.7240 - val_loss: 0.5510 - val_accuracy: 0.7210\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 171s 853ms/step - loss: 0.5013 - accuracy: 0.7573 - val_loss: 0.5049 - val_accuracy: 0.7600\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 170s 852ms/step - loss: 0.4376 - accuracy: 0.7937 - val_loss: 0.4914 - val_accuracy: 0.7810\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 170s 852ms/step - loss: 0.3934 - accuracy: 0.8227 - val_loss: 0.5300 - val_accuracy: 0.7710\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 171s 857ms/step - loss: 0.3249 - accuracy: 0.8615 - val_loss: 0.5166 - val_accuracy: 0.7900\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 171s 854ms/step - loss: 0.2535 - accuracy: 0.8930 - val_loss: 0.5630 - val_accuracy: 0.7960\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 171s 857ms/step - loss: 0.1954 - accuracy: 0.9208 - val_loss: 0.6690 - val_accuracy: 0.7720\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 171s 857ms/step - loss: 0.1433 - accuracy: 0.9455 - val_loss: 0.8721 - val_accuracy: 0.7560\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 172s 859ms/step - loss: 0.1257 - accuracy: 0.9463 - val_loss: 0.8886 - val_accuracy: 0.7690\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 171s 855ms/step - loss: 0.1076 - accuracy: 0.9635 - val_loss: 1.0151 - val_accuracy: 0.7680\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 171s 856ms/step - loss: 0.0935 - accuracy: 0.9647 - val_loss: 1.0053 - val_accuracy: 0.7840\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 169s 845ms/step - loss: 0.0862 - accuracy: 0.9720 - val_loss: 1.1292 - val_accuracy: 0.7800\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 170s 850ms/step - loss: 0.0801 - accuracy: 0.9770 - val_loss: 1.3671 - val_accuracy: 0.7620\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 170s 852ms/step - loss: 0.0796 - accuracy: 0.9758 - val_loss: 1.7143 - val_accuracy: 0.7440\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 171s 853ms/step - loss: 0.0710 - accuracy: 0.9787 - val_loss: 1.5697 - val_accuracy: 0.7800\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 171s 853ms/step - loss: 0.0888 - accuracy: 0.9745 - val_loss: 1.5976 - val_accuracy: 0.7670\n",
      "63/63 [==============================] - 19s 298ms/step - loss: 0.3572 - accuracy: 0.8390\n",
      "Test accuracy: 0.839\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Epoch 1/20\n",
      " 11/250 [>.............................] - ETA: 3:10 - loss: 0.3845 - accuracy: 0.9409"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Train the model with varying training sample sizes\n",
    "sample_sizes = [3500,4000,4500,5000]\n",
    "history_dict = []\n",
    "for size in sample_sizes:\n",
    "    # Set up the training subset\n",
    "    make_subset(\"temp_train\", start_index=1500, end_index=size)\n",
    "    make_subset(\"validation\", start_index=size, end_index=size+500)\n",
    "    make_subset(\"test\", start_index=size+500, end_index=size+1500)\n",
    "    train_dataset = image_dataset_from_directory(\n",
    "      new_base_dir / \"temp_train\", \n",
    "      image_size=(180, 180), \n",
    "      batch_size=20)\n",
    "    # Using the callbacks function to monitor validation loss and running the model\n",
    "  \n",
    "    callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")]\n",
    "\n",
    "    history = model.fit(\n",
    "      train_dataset,\n",
    "      epochs=20,\n",
    "      validation_data=validation_dataset,\n",
    "      callbacks=callbacks)\n",
    "    \n",
    "    test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
    "    test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "    history_dict.append(test_acc)\n",
    "    print(f\"Test accuracy: {test_acc:.3f}\")  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a940d23-478b-4bdb-ab39-632b43189150",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_sizes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-78f03e673383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of training samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Effect of training sample size on CNN performance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_sizes' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(sample_sizes, history_dict, 'bo-')\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.title('Effect of training sample size on CNN performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec092b-542d-4e72-bb0d-5b8c99e35bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
