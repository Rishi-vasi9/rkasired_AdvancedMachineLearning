{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "713db098-ab25-4482-af01-60dfada508de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "713db098-ab25-4482-af01-60dfada508de",
        "outputId": "90734b44-0ca1-4972-ed40-ff9b8c503589"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c066f7ca-abeb-4667-aec3-eb57d4a43350\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c066f7ca-abeb-4667-aec3-eb57d4a43350\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"rishitha2k\",\"key\":\"3f5bb49552daa6eed5944e99b92622b3\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# To upload the kaggle.json file\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6572d9d2-6cc3-4844-afca-190c4d0378f7",
      "metadata": {
        "id": "6572d9d2-6cc3-4844-afca-190c4d0378f7"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "\n",
        "# Changing the path to the .kaggle folder\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#  Changing the permissions to perform read and write access\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the dogs-vs-cats dataset\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4OufR9GS3AX",
        "outputId": "89631fae-679b-468c-863d-364f457eccab"
      },
      "id": "B4OufR9GS3AX",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            " 98% 793M/812M [00:03<00:00, 238MB/s]\n",
            "100% 812M/812M [00:03<00:00, 232MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4b740937-2a69-4e5a-b702-d98aeab4d008",
      "metadata": {
        "id": "4b740937-2a69-4e5a-b702-d98aeab4d008"
      },
      "outputs": [],
      "source": [
        "# Unzipping dogs-vs-cats dataset file\n",
        "!unzip -qq dogs-vs-cats.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now training the model from scratch"
      ],
      "metadata": {
        "id": "_082Z5lsAYea"
      },
      "id": "_082Z5lsAYea"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bd338c33-11ed-4b24-afc3-d857b6144b3a",
      "metadata": {
        "id": "bd338c33-11ed-4b24-afc3-d857b6144b3a"
      },
      "outputs": [],
      "source": [
        "# Unzipping train sample\n",
        "!unzip -o -qq train.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EfQupfrgTFa8",
        "outputId": "89490399-0b80-4e48-8f82-52e427f357d2"
      },
      "id": "EfQupfrgTFa8",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.12\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (23.5.26)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.16)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.41.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.11.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed gast-0.4.0 keras-2.12.0 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question-1"
      ],
      "metadata": {
        "id": "Vr-3CfSoCpGc"
      },
      "id": "Vr-3CfSoCpGc"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9146a3ad-1cb0-41be-92f8-0af5f6d91266",
      "metadata": {
        "id": "9146a3ad-1cb0-41be-92f8-0af5f6d91266"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "#shutil.rmtree(\"cats_vs_dogs_small\")\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1f7b5b6b-d773-4e43-b7e6-d9dfe7456ea4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f7b5b6b-d773-4e43-b7e6-d9dfe7456ea4",
        "outputId": "336bd229-f9f1-4da5-d87d-9543b3bd4def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 178, 178, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 89, 89, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 87, 87, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 43, 43, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 41, 41, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 18, 18, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 9, 9, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 12545     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 991,041\n",
            "Trainable params: 991,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Building the model and running the model summary\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ae1ca23e-99e9-4d3b-9fb8-0bb69968ffe6",
      "metadata": {
        "id": "ae1ca23e-99e9-4d3b-9fb8-0bb69968ffe6"
      },
      "outputs": [],
      "source": [
        "# Configuration of the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "924dec9e-ebad-4e03-a473-ca5b64e1c1ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "924dec9e-ebad-4e03-a473-ca5b64e1c1ad",
        "outputId": "006d3de6-ca54-477e-e93f-2d94d2bb8a26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Declaring the image size and batch size to read the images from train. validation and test directories\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8be95e14-c3b9-41c3-8aec-000b33fc68d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8be95e14-c3b9-41c3-8aec-000b33fc68d0",
        "outputId": "6c347e49-eeac-4b81-d424-6bff9a273304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 18s 102ms/step - loss: 0.7021 - accuracy: 0.5165 - val_loss: 0.7037 - val_accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.6921 - accuracy: 0.5240 - val_loss: 0.7283 - val_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.6980 - accuracy: 0.5345 - val_loss: 0.6853 - val_accuracy: 0.5410\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 7s 101ms/step - loss: 0.6846 - accuracy: 0.5670 - val_loss: 0.6760 - val_accuracy: 0.6050\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.6803 - accuracy: 0.5880 - val_loss: 0.6452 - val_accuracy: 0.6420\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 5s 68ms/step - loss: 0.6604 - accuracy: 0.6225 - val_loss: 0.6554 - val_accuracy: 0.6040\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 6s 82ms/step - loss: 0.6357 - accuracy: 0.6535 - val_loss: 0.6175 - val_accuracy: 0.6560\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.6095 - accuracy: 0.6800 - val_loss: 0.6149 - val_accuracy: 0.6510\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.5736 - accuracy: 0.6980 - val_loss: 0.6313 - val_accuracy: 0.6430\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.5561 - accuracy: 0.7190 - val_loss: 0.5873 - val_accuracy: 0.7000\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.5239 - accuracy: 0.7375 - val_loss: 0.7087 - val_accuracy: 0.6370\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 7s 101ms/step - loss: 0.5014 - accuracy: 0.7490 - val_loss: 0.6041 - val_accuracy: 0.6900\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 5s 69ms/step - loss: 0.4654 - accuracy: 0.7825 - val_loss: 0.5701 - val_accuracy: 0.7030\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 6s 88ms/step - loss: 0.4179 - accuracy: 0.8095 - val_loss: 0.5759 - val_accuracy: 0.7180\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 5s 66ms/step - loss: 0.3783 - accuracy: 0.8300 - val_loss: 0.6737 - val_accuracy: 0.6930\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.3356 - accuracy: 0.8520 - val_loss: 0.6374 - val_accuracy: 0.7460\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.2939 - accuracy: 0.8810 - val_loss: 0.7023 - val_accuracy: 0.7270\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.2419 - accuracy: 0.9005 - val_loss: 0.7270 - val_accuracy: 0.7290\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 4s 55ms/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 1.1647 - val_accuracy: 0.6840\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.1598 - accuracy: 0.9400 - val_loss: 1.1216 - val_accuracy: 0.7120\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.1187 - accuracy: 0.9570 - val_loss: 1.7116 - val_accuracy: 0.6690\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1058 - accuracy: 0.9615 - val_loss: 1.1220 - val_accuracy: 0.7280\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.0893 - accuracy: 0.9655 - val_loss: 1.2927 - val_accuracy: 0.7210\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0543 - accuracy: 0.9850 - val_loss: 2.0455 - val_accuracy: 0.6900\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 6s 84ms/step - loss: 0.0955 - accuracy: 0.9785 - val_loss: 1.3675 - val_accuracy: 0.7180\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.0628 - accuracy: 0.9850 - val_loss: 1.5216 - val_accuracy: 0.7120\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.0732 - accuracy: 0.9735 - val_loss: 1.6348 - val_accuracy: 0.6950\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 6s 97ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 1.5270 - val_accuracy: 0.7220\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.0591 - accuracy: 0.9800 - val_loss: 1.8391 - val_accuracy: 0.7140\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.0378 - accuracy: 0.9865 - val_loss: 1.7210 - val_accuracy: 0.7050\n"
          ]
        }
      ],
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0d1524ed-218c-4af9-9e10-23af61f677df",
      "metadata": {
        "id": "0d1524ed-218c-4af9-9e10-23af61f677df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f5637a-fbcd-4417-808f-52291708c217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 3s 47ms/step - loss: 0.5677 - accuracy: 0.7130\n",
            "Test accuracy: 0.713\n"
          ]
        }
      ],
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "TlQAgbHOCig8"
      },
      "id": "TlQAgbHOCig8"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d9fc90bc-dad2-4eae-a437-db4f16a1e3c2",
      "metadata": {
        "id": "d9fc90bc-dad2-4eae-a437-db4f16a1e3c2"
      },
      "outputs": [],
      "source": [
        "# Declaring Data Augumentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3376f84f-89f2-4179-9172-b64d20297441",
      "metadata": {
        "id": "3376f84f-89f2-4179-9172-b64d20297441"
      },
      "outputs": [],
      "source": [
        "# Building the model and configuing it\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "92cd7971-31b4-4ce4-a271-ab3dde56f169",
      "metadata": {
        "id": "92cd7971-31b4-4ce4-a271-ab3dde56f169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6bc321c-8e32-4900-a172-a5550f46d117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "63/63 [==============================] - 7s 65ms/step - loss: 0.7008 - accuracy: 0.4990 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
            "Epoch 2/80\n",
            "63/63 [==============================] - 6s 92ms/step - loss: 0.6941 - accuracy: 0.5010 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
            "Epoch 3/80\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.6989 - accuracy: 0.5210 - val_loss: 0.6881 - val_accuracy: 0.6030\n",
            "Epoch 4/80\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.6889 - accuracy: 0.5630 - val_loss: 0.6769 - val_accuracy: 0.5870\n",
            "Epoch 5/80\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.6740 - accuracy: 0.5870 - val_loss: 0.6686 - val_accuracy: 0.5970\n",
            "Epoch 6/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.6434 - accuracy: 0.6475 - val_loss: 0.6247 - val_accuracy: 0.6320\n",
            "Epoch 7/80\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.6197 - accuracy: 0.6480 - val_loss: 0.6118 - val_accuracy: 0.6660\n",
            "Epoch 8/80\n",
            "63/63 [==============================] - 7s 100ms/step - loss: 0.6085 - accuracy: 0.6625 - val_loss: 0.6176 - val_accuracy: 0.6380\n",
            "Epoch 9/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.5985 - accuracy: 0.6880 - val_loss: 0.5758 - val_accuracy: 0.6920\n",
            "Epoch 10/80\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.6004 - accuracy: 0.6785 - val_loss: 0.5715 - val_accuracy: 0.6930\n",
            "Epoch 11/80\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.5764 - accuracy: 0.6980 - val_loss: 0.6025 - val_accuracy: 0.6760\n",
            "Epoch 12/80\n",
            "63/63 [==============================] - 5s 66ms/step - loss: 0.5675 - accuracy: 0.6965 - val_loss: 0.5536 - val_accuracy: 0.7250\n",
            "Epoch 13/80\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.5506 - accuracy: 0.7160 - val_loss: 0.6198 - val_accuracy: 0.6520\n",
            "Epoch 14/80\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.5380 - accuracy: 0.7295 - val_loss: 0.5081 - val_accuracy: 0.7540\n",
            "Epoch 15/80\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.5360 - accuracy: 0.7380 - val_loss: 0.5069 - val_accuracy: 0.7600\n",
            "Epoch 16/80\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.5058 - accuracy: 0.7560 - val_loss: 0.5158 - val_accuracy: 0.7600\n",
            "Epoch 17/80\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.5041 - accuracy: 0.7435 - val_loss: 0.5996 - val_accuracy: 0.7010\n",
            "Epoch 18/80\n",
            "63/63 [==============================] - 6s 86ms/step - loss: 0.4946 - accuracy: 0.7560 - val_loss: 0.5726 - val_accuracy: 0.7070\n",
            "Epoch 19/80\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.4991 - accuracy: 0.7600 - val_loss: 0.4826 - val_accuracy: 0.7800\n",
            "Epoch 20/80\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.4849 - accuracy: 0.7720 - val_loss: 0.4811 - val_accuracy: 0.7840\n",
            "Epoch 21/80\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.4773 - accuracy: 0.7760 - val_loss: 0.4633 - val_accuracy: 0.7800\n",
            "Epoch 22/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.4654 - accuracy: 0.7745 - val_loss: 0.5687 - val_accuracy: 0.7590\n",
            "Epoch 23/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.4690 - accuracy: 0.7860 - val_loss: 0.5013 - val_accuracy: 0.7940\n",
            "Epoch 24/80\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.4427 - accuracy: 0.7960 - val_loss: 0.4623 - val_accuracy: 0.7850\n",
            "Epoch 25/80\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.4404 - accuracy: 0.8095 - val_loss: 0.4537 - val_accuracy: 0.7970\n",
            "Epoch 26/80\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.4406 - accuracy: 0.7915 - val_loss: 0.4381 - val_accuracy: 0.8010\n",
            "Epoch 27/80\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.4379 - accuracy: 0.8045 - val_loss: 0.4711 - val_accuracy: 0.8070\n",
            "Epoch 28/80\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.4170 - accuracy: 0.8105 - val_loss: 0.4679 - val_accuracy: 0.7950\n",
            "Epoch 29/80\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.4216 - accuracy: 0.8165 - val_loss: 0.4105 - val_accuracy: 0.8200\n",
            "Epoch 30/80\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.4170 - accuracy: 0.8140 - val_loss: 0.4280 - val_accuracy: 0.8110\n",
            "Epoch 31/80\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.4055 - accuracy: 0.8165 - val_loss: 0.5582 - val_accuracy: 0.7710\n",
            "Epoch 32/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.4159 - accuracy: 0.8155 - val_loss: 0.5205 - val_accuracy: 0.7970\n",
            "Epoch 33/80\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.3961 - accuracy: 0.8250 - val_loss: 0.4360 - val_accuracy: 0.8100\n",
            "Epoch 34/80\n",
            "63/63 [==============================] - 5s 66ms/step - loss: 0.3895 - accuracy: 0.8315 - val_loss: 0.4501 - val_accuracy: 0.8150\n",
            "Epoch 35/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.3776 - accuracy: 0.8295 - val_loss: 0.4237 - val_accuracy: 0.8120\n",
            "Epoch 36/80\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.3618 - accuracy: 0.8385 - val_loss: 0.4883 - val_accuracy: 0.8320\n",
            "Epoch 37/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.3511 - accuracy: 0.8565 - val_loss: 0.4473 - val_accuracy: 0.8230\n",
            "Epoch 38/80\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.3494 - accuracy: 0.8440 - val_loss: 0.5365 - val_accuracy: 0.7790\n",
            "Epoch 39/80\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.3386 - accuracy: 0.8455 - val_loss: 0.6270 - val_accuracy: 0.7920\n",
            "Epoch 40/80\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.3369 - accuracy: 0.8570 - val_loss: 0.4631 - val_accuracy: 0.8410\n",
            "Epoch 41/80\n",
            "63/63 [==============================] - 6s 82ms/step - loss: 0.3343 - accuracy: 0.8575 - val_loss: 0.3920 - val_accuracy: 0.8310\n",
            "Epoch 42/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.3253 - accuracy: 0.8665 - val_loss: 0.4220 - val_accuracy: 0.8050\n",
            "Epoch 43/80\n",
            "63/63 [==============================] - 7s 100ms/step - loss: 0.3131 - accuracy: 0.8635 - val_loss: 0.5062 - val_accuracy: 0.7960\n",
            "Epoch 44/80\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.3300 - accuracy: 0.8630 - val_loss: 0.4473 - val_accuracy: 0.8160\n",
            "Epoch 45/80\n",
            "63/63 [==============================] - 7s 102ms/step - loss: 0.3054 - accuracy: 0.8705 - val_loss: 0.4820 - val_accuracy: 0.8370\n",
            "Epoch 46/80\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.2873 - accuracy: 0.8765 - val_loss: 0.3993 - val_accuracy: 0.8320\n",
            "Epoch 47/80\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.3012 - accuracy: 0.8785 - val_loss: 0.4282 - val_accuracy: 0.8460\n",
            "Epoch 48/80\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.2849 - accuracy: 0.8680 - val_loss: 0.4243 - val_accuracy: 0.8480\n",
            "Epoch 49/80\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.2883 - accuracy: 0.8750 - val_loss: 0.4538 - val_accuracy: 0.8290\n",
            "Epoch 50/80\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.2688 - accuracy: 0.8895 - val_loss: 0.4572 - val_accuracy: 0.8150\n",
            "Epoch 51/80\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2742 - accuracy: 0.8800 - val_loss: 0.7403 - val_accuracy: 0.8000\n",
            "Epoch 52/80\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2570 - accuracy: 0.8910 - val_loss: 0.5949 - val_accuracy: 0.8020\n",
            "Epoch 53/80\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.2488 - accuracy: 0.8985 - val_loss: 0.5184 - val_accuracy: 0.8150\n",
            "Epoch 54/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.2913 - accuracy: 0.8840 - val_loss: 0.4385 - val_accuracy: 0.8470\n",
            "Epoch 55/80\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2449 - accuracy: 0.8975 - val_loss: 0.6053 - val_accuracy: 0.7910\n",
            "Epoch 56/80\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.2470 - accuracy: 0.9010 - val_loss: 0.3951 - val_accuracy: 0.8520\n",
            "Epoch 57/80\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.2434 - accuracy: 0.8920 - val_loss: 0.6034 - val_accuracy: 0.8100\n",
            "Epoch 58/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.2559 - accuracy: 0.9020 - val_loss: 0.5041 - val_accuracy: 0.8370\n",
            "Epoch 59/80\n",
            "63/63 [==============================] - 6s 99ms/step - loss: 0.2400 - accuracy: 0.9075 - val_loss: 0.5316 - val_accuracy: 0.8230\n",
            "Epoch 60/80\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2295 - accuracy: 0.9045 - val_loss: 0.5300 - val_accuracy: 0.8480\n",
            "Epoch 61/80\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.2354 - accuracy: 0.9015 - val_loss: 0.6125 - val_accuracy: 0.8380\n",
            "Epoch 62/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.2218 - accuracy: 0.9080 - val_loss: 0.5024 - val_accuracy: 0.8320\n",
            "Epoch 63/80\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.2103 - accuracy: 0.9130 - val_loss: 0.5594 - val_accuracy: 0.8520\n",
            "Epoch 64/80\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.1994 - accuracy: 0.9130 - val_loss: 0.4579 - val_accuracy: 0.8390\n",
            "Epoch 65/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.2236 - accuracy: 0.9090 - val_loss: 0.7238 - val_accuracy: 0.8240\n",
            "Epoch 66/80\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1947 - accuracy: 0.9225 - val_loss: 0.4131 - val_accuracy: 0.8590\n",
            "Epoch 67/80\n",
            "63/63 [==============================] - 7s 101ms/step - loss: 0.2110 - accuracy: 0.9190 - val_loss: 0.5748 - val_accuracy: 0.8380\n",
            "Epoch 68/80\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2195 - accuracy: 0.9110 - val_loss: 0.4648 - val_accuracy: 0.8320\n",
            "Epoch 69/80\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2010 - accuracy: 0.9165 - val_loss: 0.7683 - val_accuracy: 0.8360\n",
            "Epoch 70/80\n",
            "63/63 [==============================] - 6s 96ms/step - loss: 0.1758 - accuracy: 0.9325 - val_loss: 0.5936 - val_accuracy: 0.8560\n",
            "Epoch 71/80\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1978 - accuracy: 0.9250 - val_loss: 1.1192 - val_accuracy: 0.7920\n",
            "Epoch 72/80\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1961 - accuracy: 0.9295 - val_loss: 0.5151 - val_accuracy: 0.8340\n",
            "Epoch 73/80\n",
            "63/63 [==============================] - 6s 82ms/step - loss: 0.1960 - accuracy: 0.9280 - val_loss: 0.4733 - val_accuracy: 0.8560\n",
            "Epoch 74/80\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.1757 - accuracy: 0.9315 - val_loss: 0.4981 - val_accuracy: 0.8470\n",
            "Epoch 75/80\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2016 - accuracy: 0.9185 - val_loss: 0.5241 - val_accuracy: 0.8340\n",
            "Epoch 76/80\n",
            "63/63 [==============================] - 6s 99ms/step - loss: 0.1724 - accuracy: 0.9365 - val_loss: 0.5977 - val_accuracy: 0.8440\n",
            "Epoch 77/80\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.1878 - accuracy: 0.9250 - val_loss: 0.5214 - val_accuracy: 0.8520\n",
            "Epoch 78/80\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1723 - accuracy: 0.9360 - val_loss: 0.5011 - val_accuracy: 0.8550\n",
            "Epoch 79/80\n",
            "63/63 [==============================] - 6s 82ms/step - loss: 0.2020 - accuracy: 0.9265 - val_loss: 0.4908 - val_accuracy: 0.8540\n",
            "Epoch 80/80\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1592 - accuracy: 0.9455 - val_loss: 0.4933 - val_accuracy: 0.8490\n"
          ]
        }
      ],
      "source": [
        "\n",
        "   # Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_the_scratch_with_dataaugmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=80,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "651a0652-3bc1-4d7c-a679-36a08c224eda",
      "metadata": {
        "id": "651a0652-3bc1-4d7c-a679-36a08c224eda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41fe5c23-22f6-4d6b-9e22-10977025eb64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 5s 64ms/step - loss: 0.4519 - accuracy: 0.8245\n",
            "Test accuracy: 0.825\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_the_scratch_with_dataaugmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question-2"
      ],
      "metadata": {
        "id": "60DfV6thC1AI"
      },
      "id": "60DfV6thC1AI"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2a21f187-fd0f-4097-b5d2-62f4995f8814",
      "metadata": {
        "id": "2a21f187-fd0f-4097-b5d2-62f4995f8814"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "# Increasing the training sample from 1000 to 2000\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "#shutil.rmtree(\"cats_vs_dogs_small_IncreasedTrainSample\")\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_IncreasedTrainSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 2000 samples, test has 1000 samples, and validation has 500 samples\n",
        "make_subset(\"train\", start_index=0, end_index=2000)\n",
        "make_subset(\"validation\", start_index=2000, end_index=2500)\n",
        "make_subset(\"test\", start_index=2500, end_index=3500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "811e0e5c-8a01-4d1e-a12d-e7a84eb884fa",
      "metadata": {
        "id": "811e0e5c-8a01-4d1e-a12d-e7a84eb884fa"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "399ec1d9-b5ad-408b-94d6-eedaa4dff28b",
      "metadata": {
        "id": "399ec1d9-b5ad-408b-94d6-eedaa4dff28b"
      },
      "outputs": [],
      "source": [
        "# Configuring the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b77aea18-3651-49b6-93ad-568f6d0c3a67",
      "metadata": {
        "id": "b77aea18-3651-49b6-93ad-568f6d0c3a67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33618e19-fa5c-45d0-ef5f-ac7c08b11f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 6s 60ms/step - loss: 0.7340 - accuracy: 0.4985 - val_loss: 0.6925 - val_accuracy: 0.5290\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.6957 - accuracy: 0.5220 - val_loss: 0.6868 - val_accuracy: 0.6010\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.6914 - accuracy: 0.5425 - val_loss: 0.6910 - val_accuracy: 0.5030\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.6914 - accuracy: 0.6010 - val_loss: 0.6672 - val_accuracy: 0.6030\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.6486 - accuracy: 0.6365 - val_loss: 0.7636 - val_accuracy: 0.5510\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.6078 - accuracy: 0.6810 - val_loss: 0.6240 - val_accuracy: 0.6370\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.5874 - accuracy: 0.6860 - val_loss: 0.6516 - val_accuracy: 0.6680\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.5806 - accuracy: 0.6920 - val_loss: 0.6068 - val_accuracy: 0.6800\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.5314 - accuracy: 0.7305 - val_loss: 0.5574 - val_accuracy: 0.7070\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 6s 82ms/step - loss: 0.5017 - accuracy: 0.7500 - val_loss: 0.5445 - val_accuracy: 0.7210\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.4731 - accuracy: 0.7675 - val_loss: 0.5977 - val_accuracy: 0.6780\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.4090 - accuracy: 0.8105 - val_loss: 0.6236 - val_accuracy: 0.6850\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.3872 - accuracy: 0.8285 - val_loss: 0.5594 - val_accuracy: 0.7440\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.3424 - accuracy: 0.8475 - val_loss: 0.9646 - val_accuracy: 0.6880\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.2911 - accuracy: 0.8750 - val_loss: 0.7742 - val_accuracy: 0.7100\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.2278 - accuracy: 0.9065 - val_loss: 0.9622 - val_accuracy: 0.7170\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1934 - accuracy: 0.9250 - val_loss: 0.7600 - val_accuracy: 0.7630\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 6s 80ms/step - loss: 0.1489 - accuracy: 0.9425 - val_loss: 1.0414 - val_accuracy: 0.6880\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1138 - accuracy: 0.9565 - val_loss: 1.3819 - val_accuracy: 0.6970\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1039 - accuracy: 0.9565 - val_loss: 1.0509 - val_accuracy: 0.7370\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0728 - accuracy: 0.9730 - val_loss: 1.4559 - val_accuracy: 0.6990\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.0679 - accuracy: 0.9785 - val_loss: 1.2740 - val_accuracy: 0.7440\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.0610 - accuracy: 0.9780 - val_loss: 2.5175 - val_accuracy: 0.6660\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0702 - accuracy: 0.9745 - val_loss: 1.7289 - val_accuracy: 0.7200\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0490 - accuracy: 0.9835 - val_loss: 1.5835 - val_accuracy: 0.7300\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.0434 - accuracy: 0.9865 - val_loss: 2.3185 - val_accuracy: 0.7260\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.0921 - accuracy: 0.9780 - val_loss: 1.5788 - val_accuracy: 0.7630\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0511 - accuracy: 0.9870 - val_loss: 1.4341 - val_accuracy: 0.7450\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.0457 - accuracy: 0.9875 - val_loss: 1.4524 - val_accuracy: 0.7480\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.0794 - accuracy: 0.9830 - val_loss: 1.9422 - val_accuracy: 0.7460\n"
          ]
        }
      ],
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "98032523-4346-4d70-b3fa-91d402f9fcf7",
      "metadata": {
        "id": "98032523-4346-4d70-b3fa-91d402f9fcf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b56280a-cb45-40a9-ce34-dd3b0c132e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 3s 34ms/step - loss: 0.5587 - accuracy: 0.7200\n",
            "Test accuracy: 0.720\n"
          ]
        }
      ],
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question-3"
      ],
      "metadata": {
        "id": "z8sf67shEKLR"
      },
      "id": "z8sf67shEKLR"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d61bcaf0-96fc-4018-968c-51d9de528119",
      "metadata": {
        "id": "d61bcaf0-96fc-4018-968c-51d9de528119"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "# Increasing the training sample from 1000 to 2000\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_OptimalTrainSamples1\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Trainingset has 1500 samples, testset has 1000 samples, and validationset has 500 samples\n",
        "# make_subset(\"train\", start_index=0, end_index=3500)\n",
        "# make_subset(\"validation\", start_index=2500, end_index=3000)\n",
        "# make_subset(\"test\", start_index=3000, end_index=4000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "cce1fd57-3e19-40f0-85d2-0d45bfd61459",
      "metadata": {
        "id": "cce1fd57-3e19-40f0-85d2-0d45bfd61459"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1ca82bbd-79c5-4c5b-9ab4-c5ae0e8cd47c",
      "metadata": {
        "id": "1ca82bbd-79c5-4c5b-9ab4-c5ae0e8cd47c"
      },
      "outputs": [],
      "source": [
        "# Configuring the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6b418415-ffa3-4bac-ac4f-2eecee36781b",
      "metadata": {
        "id": "6b418415-ffa3-4bac-ac4f-2eecee36781b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13c4a91-98b0-4801-8556-a0b1c5703ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 12s 44ms/step - loss: 0.7024 - accuracy: 0.5042 - val_loss: 0.6876 - val_accuracy: 0.5540\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.6777 - accuracy: 0.5888 - val_loss: 0.6690 - val_accuracy: 0.5800\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.6351 - accuracy: 0.6348 - val_loss: 0.8464 - val_accuracy: 0.6310\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.5896 - accuracy: 0.6877 - val_loss: 0.5792 - val_accuracy: 0.6890\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 7s 32ms/step - loss: 0.5338 - accuracy: 0.7310 - val_loss: 0.5656 - val_accuracy: 0.7040\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.4962 - accuracy: 0.7655 - val_loss: 0.4699 - val_accuracy: 0.7790\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 7s 32ms/step - loss: 0.4443 - accuracy: 0.7930 - val_loss: 0.4998 - val_accuracy: 0.7570\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.3941 - accuracy: 0.8220 - val_loss: 0.4898 - val_accuracy: 0.7820\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 7s 32ms/step - loss: 0.3383 - accuracy: 0.8545 - val_loss: 0.5295 - val_accuracy: 0.7820\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 0.2815 - accuracy: 0.8792 - val_loss: 0.5181 - val_accuracy: 0.7860\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 10s 49ms/step - loss: 0.2227 - accuracy: 0.9013 - val_loss: 0.5039 - val_accuracy: 0.7970\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1775 - accuracy: 0.9298 - val_loss: 0.6698 - val_accuracy: 0.7890\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 7s 32ms/step - loss: 0.1362 - accuracy: 0.9465 - val_loss: 0.8255 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 10s 49ms/step - loss: 0.1078 - accuracy: 0.9588 - val_loss: 0.9021 - val_accuracy: 0.7970\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 7s 32ms/step - loss: 0.0919 - accuracy: 0.9697 - val_loss: 1.0928 - val_accuracy: 0.7610\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.0840 - accuracy: 0.9710 - val_loss: 0.8973 - val_accuracy: 0.8060\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.0838 - accuracy: 0.9703 - val_loss: 1.0468 - val_accuracy: 0.7950\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.0663 - accuracy: 0.9750 - val_loss: 1.1671 - val_accuracy: 0.7990\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0637 - accuracy: 0.9775 - val_loss: 1.3077 - val_accuracy: 0.7880\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.0709 - accuracy: 0.9768 - val_loss: 1.5397 - val_accuracy: 0.7670\n",
            "63/63 [==============================] - 3s 35ms/step - loss: 0.3912 - accuracy: 0.8305\n",
            "Test accuracy: 0.831\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.2603 - accuracy: 0.9274 - val_loss: 0.6065 - val_accuracy: 0.8030\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 0.1147 - accuracy: 0.9608 - val_loss: 0.7971 - val_accuracy: 0.7750\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0696 - accuracy: 0.9722 - val_loss: 0.9544 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 0.0811 - accuracy: 0.9746 - val_loss: 1.0370 - val_accuracy: 0.8050\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 10s 37ms/step - loss: 0.0805 - accuracy: 0.9758 - val_loss: 1.5190 - val_accuracy: 0.7730\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 1.3572 - val_accuracy: 0.8050\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 0.0744 - accuracy: 0.9806 - val_loss: 1.4676 - val_accuracy: 0.8060\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0559 - accuracy: 0.9818 - val_loss: 1.6376 - val_accuracy: 0.8040\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 0.0593 - accuracy: 0.9848 - val_loss: 1.6353 - val_accuracy: 0.7910\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 11s 41ms/step - loss: 0.0646 - accuracy: 0.9842 - val_loss: 1.8294 - val_accuracy: 0.7990\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0640 - accuracy: 0.9840 - val_loss: 1.6945 - val_accuracy: 0.8100\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 0.0514 - accuracy: 0.9858 - val_loss: 1.9668 - val_accuracy: 0.7890\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 9s 36ms/step - loss: 0.0638 - accuracy: 0.9838 - val_loss: 1.8184 - val_accuracy: 0.7980\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0614 - accuracy: 0.9852 - val_loss: 2.2344 - val_accuracy: 0.7960\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 0.0645 - accuracy: 0.9860 - val_loss: 1.8339 - val_accuracy: 0.7940\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0685 - accuracy: 0.9864 - val_loss: 2.2677 - val_accuracy: 0.8000\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 0.0614 - accuracy: 0.9854 - val_loss: 2.5741 - val_accuracy: 0.8020\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0580 - accuracy: 0.9856 - val_loss: 3.0493 - val_accuracy: 0.7910\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0733 - accuracy: 0.9856 - val_loss: 3.0443 - val_accuracy: 0.8050\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.0754 - accuracy: 0.9836 - val_loss: 2.6183 - val_accuracy: 0.8140\n",
            "63/63 [==============================] - 3s 34ms/step - loss: 0.0795 - accuracy: 0.9745\n",
            "Test accuracy: 0.975\n",
            "Found 6000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "300/300 [==============================] - 13s 41ms/step - loss: 0.2915 - accuracy: 0.9412 - val_loss: 0.7241 - val_accuracy: 0.7950\n",
            "Epoch 2/20\n",
            "300/300 [==============================] - 11s 36ms/step - loss: 0.1101 - accuracy: 0.9660 - val_loss: 1.2757 - val_accuracy: 0.8010\n",
            "Epoch 3/20\n",
            "300/300 [==============================] - 12s 41ms/step - loss: 0.0872 - accuracy: 0.9770 - val_loss: 1.1968 - val_accuracy: 0.7860\n",
            "Epoch 4/20\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.0685 - accuracy: 0.9798 - val_loss: 1.6462 - val_accuracy: 0.8030\n",
            "Epoch 5/20\n",
            "300/300 [==============================] - 10s 33ms/step - loss: 0.0734 - accuracy: 0.9815 - val_loss: 1.9309 - val_accuracy: 0.8110\n",
            "Epoch 6/20\n",
            "300/300 [==============================] - 15s 48ms/step - loss: 0.0740 - accuracy: 0.9838 - val_loss: 1.9224 - val_accuracy: 0.8040\n",
            "Epoch 7/20\n",
            "300/300 [==============================] - 13s 42ms/step - loss: 0.0657 - accuracy: 0.9848 - val_loss: 2.0686 - val_accuracy: 0.8270\n",
            "Epoch 8/20\n",
            "300/300 [==============================] - 13s 42ms/step - loss: 0.0615 - accuracy: 0.9865 - val_loss: 2.0426 - val_accuracy: 0.7960\n",
            "Epoch 9/20\n",
            "300/300 [==============================] - 12s 41ms/step - loss: 0.0638 - accuracy: 0.9862 - val_loss: 2.3318 - val_accuracy: 0.7910\n",
            "Epoch 10/20\n",
            "300/300 [==============================] - 12s 41ms/step - loss: 0.0686 - accuracy: 0.9867 - val_loss: 2.5586 - val_accuracy: 0.8130\n",
            "Epoch 11/20\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.0866 - accuracy: 0.9860 - val_loss: 2.4653 - val_accuracy: 0.8150\n",
            "Epoch 12/20\n",
            "300/300 [==============================] - 12s 40ms/step - loss: 0.0768 - accuracy: 0.9868 - val_loss: 2.0292 - val_accuracy: 0.8380\n",
            "Epoch 13/20\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.0582 - accuracy: 0.9900 - val_loss: 2.2624 - val_accuracy: 0.7880\n",
            "Epoch 14/20\n",
            "300/300 [==============================] - 10s 33ms/step - loss: 0.0738 - accuracy: 0.9875 - val_loss: 2.5244 - val_accuracy: 0.8140\n",
            "Epoch 15/20\n",
            "300/300 [==============================] - 13s 42ms/step - loss: 0.0988 - accuracy: 0.9842 - val_loss: 2.7064 - val_accuracy: 0.7910\n",
            "Epoch 16/20\n",
            "300/300 [==============================] - 12s 41ms/step - loss: 0.0821 - accuracy: 0.9870 - val_loss: 2.7814 - val_accuracy: 0.8160\n",
            "Epoch 17/20\n",
            "300/300 [==============================] - 13s 42ms/step - loss: 0.0747 - accuracy: 0.9897 - val_loss: 4.1355 - val_accuracy: 0.8030\n",
            "Epoch 18/20\n",
            "300/300 [==============================] - 12s 40ms/step - loss: 0.0803 - accuracy: 0.9867 - val_loss: 3.2514 - val_accuracy: 0.8300\n",
            "Epoch 19/20\n",
            "300/300 [==============================] - 13s 42ms/step - loss: 0.0760 - accuracy: 0.9882 - val_loss: 4.0952 - val_accuracy: 0.7960\n",
            "Epoch 20/20\n",
            "300/300 [==============================] - 13s 42ms/step - loss: 0.1025 - accuracy: 0.9865 - val_loss: 4.0871 - val_accuracy: 0.7780\n",
            "63/63 [==============================] - 3s 38ms/step - loss: 0.0611 - accuracy: 0.9785\n",
            "Test accuracy: 0.979\n",
            "Found 7000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.3550 - accuracy: 0.9451 - val_loss: 1.2305 - val_accuracy: 0.8100\n",
            "Epoch 2/20\n",
            "350/350 [==============================] - 14s 39ms/step - loss: 0.1418 - accuracy: 0.9680 - val_loss: 1.2125 - val_accuracy: 0.8100\n",
            "Epoch 3/20\n",
            "350/350 [==============================] - 12s 34ms/step - loss: 0.0919 - accuracy: 0.9759 - val_loss: 1.4395 - val_accuracy: 0.8070\n",
            "Epoch 4/20\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.0818 - accuracy: 0.9803 - val_loss: 1.9423 - val_accuracy: 0.8200\n",
            "Epoch 5/20\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.0834 - accuracy: 0.9817 - val_loss: 2.3119 - val_accuracy: 0.8080\n",
            "Epoch 6/20\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.0632 - accuracy: 0.9870 - val_loss: 2.2935 - val_accuracy: 0.8170\n",
            "Epoch 7/20\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.0767 - accuracy: 0.9860 - val_loss: 2.3901 - val_accuracy: 0.8120\n",
            "Epoch 8/20\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.0936 - accuracy: 0.9856 - val_loss: 2.7905 - val_accuracy: 0.8300\n",
            "Epoch 9/20\n",
            "350/350 [==============================] - 14s 39ms/step - loss: 0.0828 - accuracy: 0.9869 - val_loss: 2.6688 - val_accuracy: 0.8370\n",
            "Epoch 10/20\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.0629 - accuracy: 0.9897 - val_loss: 3.5063 - val_accuracy: 0.8210\n",
            "Epoch 11/20\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.0966 - accuracy: 0.9861 - val_loss: 2.9312 - val_accuracy: 0.8110\n",
            "Epoch 12/20\n",
            "350/350 [==============================] - 14s 41ms/step - loss: 0.0972 - accuracy: 0.9886 - val_loss: 3.1613 - val_accuracy: 0.8240\n",
            "Epoch 13/20\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.1206 - accuracy: 0.9860 - val_loss: 3.6925 - val_accuracy: 0.8290\n",
            "Epoch 14/20\n",
            "350/350 [==============================] - 15s 41ms/step - loss: 0.0991 - accuracy: 0.9874 - val_loss: 3.7733 - val_accuracy: 0.8170\n",
            "Epoch 15/20\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.1121 - accuracy: 0.9856 - val_loss: 4.3423 - val_accuracy: 0.8370\n",
            "Epoch 16/20\n",
            "350/350 [==============================] - 14s 41ms/step - loss: 0.1001 - accuracy: 0.9893 - val_loss: 5.1672 - val_accuracy: 0.8300\n",
            "Epoch 17/20\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.0978 - accuracy: 0.9887 - val_loss: 4.0936 - val_accuracy: 0.8250\n",
            "Epoch 18/20\n",
            "350/350 [==============================] - 14s 38ms/step - loss: 0.0900 - accuracy: 0.9886 - val_loss: 4.5632 - val_accuracy: 0.8180\n",
            "Epoch 19/20\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.1105 - accuracy: 0.9886 - val_loss: 4.4031 - val_accuracy: 0.8240\n",
            "Epoch 20/20\n",
            "350/350 [==============================] - 13s 38ms/step - loss: 0.1321 - accuracy: 0.9893 - val_loss: 4.6834 - val_accuracy: 0.8060\n",
            "63/63 [==============================] - 3s 39ms/step - loss: 0.0880 - accuracy: 0.9730\n",
            "Test accuracy: 0.973\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Train the model with varying training sample sizes\n",
        "sample_sizes = [3500,4000,4500,5000]\n",
        "history_dict = []\n",
        "for size in sample_sizes:\n",
        "    # Set up the training subset\n",
        "    make_subset(\"temp_train\", start_index=1500, end_index=size)\n",
        "    make_subset(\"validation\", start_index=size, end_index=size+500)\n",
        "    make_subset(\"test\", start_index=size+500, end_index=size+1500)\n",
        "    train_dataset = image_dataset_from_directory(\n",
        "      new_base_dir / \"temp_train\",\n",
        "      image_size=(180, 180),\n",
        "      batch_size=20)\n",
        "    # Using the callbacks function to monitor validation loss and running the model\n",
        "\n",
        "    callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_variedtrain.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")]\n",
        "\n",
        "    history = model.fit(\n",
        "      train_dataset,\n",
        "      epochs=20,\n",
        "      validation_data=validation_dataset,\n",
        "      callbacks=callbacks)\n",
        "\n",
        "    test_model = keras.models.load_model(\"convnet_from_scratch_variedtrain.keras\")\n",
        "    test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "    history_dict.append(test_acc)\n",
        "    print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6a940d23-478b-4bdb-ab39-632b43189150",
      "metadata": {
        "id": "6a940d23-478b-4bdb-ab39-632b43189150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "b7580b68-1b33-44c9-a656-4139535d1580"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(sample_sizes, history_dict, 'bo-')\n",
        "plt.xlabel('Number of training samples')\n",
        "plt.ylabel('Test accuracy')\n",
        "plt.title('Effect of training sample size on CNN performance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-trained network\n",
        "\n",
        "Question-4"
      ],
      "metadata": {
        "id": "8nKw3a67FPW_"
      },
      "id": "8nKw3a67FPW_"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c1ec092b-542d-4e72-bb0d-5b8c99e35bc4",
      "metadata": {
        "id": "c1ec092b-542d-4e72-bb0d-5b8c99e35bc4"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_Pretrained\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 1500 samples, test has 500 samples, and validation has 500 samples\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))\n",
        "conv_base.summary()\n"
      ],
      "metadata": {
        "id": "ZKsjMOXzFbya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4348d033-b577-4079-d9d0-9fbcd9df4a96"
      },
      "id": "ZKsjMOXzFbya",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function to extract features and labels\n",
        "import numpy as np\n",
        "\n",
        "def get_features_and_labels(dataset):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    for images, labels in dataset:\n",
        "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
        "        features = conv_base.predict(preprocessed_images)\n",
        "        all_features.append(features)\n",
        "        all_labels.append(labels)\n",
        "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
        "# Extracting the features and labels from datasets\n",
        "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
        "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
        "test_features, test_labels =  get_features_and_labels(test_dataset)\n",
        "train_features.shape"
      ],
      "metadata": {
        "id": "pnFWlZjpFuUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3a4ebe-67cb-458f-e701-f54278dfe3b8"
      },
      "id": "pnFWlZjpFuUu",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 473ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 1s 568ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 5, 5, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Running the callback function to monitor validation loss\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "C9xCIIu_Fv9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7493bf-ea6c-4621-ec51-67be1e127bca"
      },
      "id": "C9xCIIu_Fv9m",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 3s 6ms/step - loss: 9.0417 - accuracy: 0.9504 - val_loss: 7.1285 - val_accuracy: 0.9590\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 4.0040 - accuracy: 0.9761 - val_loss: 4.3963 - val_accuracy: 0.9710\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6665 - accuracy: 0.9883 - val_loss: 5.5616 - val_accuracy: 0.9650\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.4904 - accuracy: 0.9893 - val_loss: 4.2751 - val_accuracy: 0.9720\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.3788 - accuracy: 0.9893 - val_loss: 4.1123 - val_accuracy: 0.9690\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4918 - accuracy: 0.9953 - val_loss: 5.0120 - val_accuracy: 0.9700\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5729 - accuracy: 0.9944 - val_loss: 4.7993 - val_accuracy: 0.9730\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.4615 - accuracy: 0.9970 - val_loss: 4.9125 - val_accuracy: 0.9720\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.4237 - accuracy: 0.9963 - val_loss: 4.9683 - val_accuracy: 0.9740\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.3393 - accuracy: 0.9967 - val_loss: 4.1843 - val_accuracy: 0.9790\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.4752 - accuracy: 0.9960 - val_loss: 4.9502 - val_accuracy: 0.9770\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.2068 - accuracy: 0.9973 - val_loss: 3.9965 - val_accuracy: 0.9740\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.3063 - accuracy: 0.9971 - val_loss: 7.5808 - val_accuracy: 0.9720\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.1375 - accuracy: 0.9981 - val_loss: 4.9712 - val_accuracy: 0.9740\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2259 - accuracy: 0.9976 - val_loss: 4.1594 - val_accuracy: 0.9770\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2328 - accuracy: 0.9987 - val_loss: 4.6313 - val_accuracy: 0.9740\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0858 - accuracy: 0.9983 - val_loss: 5.1225 - val_accuracy: 0.9710\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9980 - val_loss: 5.3278 - val_accuracy: 0.9750\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1093 - accuracy: 0.9986 - val_loss: 5.2977 - val_accuracy: 0.9750\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1150 - accuracy: 0.9986 - val_loss: 5.0232 - val_accuracy: 0.9760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "IN-IdI1IF6du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ef37c1-7043-4765-9629-0f2ffa3600f3"
      },
      "id": "IN-IdI1IF6du",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9995\n",
            "Test accuracy: 0.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to the VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "# Freezing the layers of the pretrained CNN\n",
        "conv_base.trainable = False\n",
        "\n",
        "# UnFreezing the layers of the pretrained CNN\n",
        "conv_base.trainable = True\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"before freezing the conv base:\", len(conv_base.trainable_weights))\n",
        "conv_base.trainable = False\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"after freezing the conv base:\", len(conv_base.trainable_weights))"
      ],
      "metadata": {
        "id": "DjC8L91OF7qk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86cec8e0-067a-44cc-90d6-f51ee1c29aee"
      },
      "id": "DjC8L91OF7qk",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 26\n",
            "This is the number of trainable weights after freezing the conv base: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Declaring Data Augumentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "# Building the model and configuring it\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "fldEFqgtGGUl"
      },
      "id": "fldEFqgtGGUl",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=50,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)\n",
        "\n"
      ],
      "metadata": {
        "id": "j9__6kGdGINF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc695cd-b622-4127-88f6-5e4183b88d41"
      },
      "id": "j9__6kGdGINF",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "350/350 [==============================] - 18s 43ms/step - loss: 10.0112 - accuracy: 0.9303 - val_loss: 5.3365 - val_accuracy: 0.9690\n",
            "Epoch 2/50\n",
            "350/350 [==============================] - 15s 41ms/step - loss: 6.4778 - accuracy: 0.9513 - val_loss: 5.0613 - val_accuracy: 0.9650\n",
            "Epoch 3/50\n",
            "350/350 [==============================] - 14s 39ms/step - loss: 3.7714 - accuracy: 0.9550 - val_loss: 2.0729 - val_accuracy: 0.9760\n",
            "Epoch 4/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 2.1393 - accuracy: 0.9581 - val_loss: 1.0183 - val_accuracy: 0.9740\n",
            "Epoch 5/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.4064 - accuracy: 0.9597 - val_loss: 0.6964 - val_accuracy: 0.9810\n",
            "Epoch 6/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 1.1158 - accuracy: 0.9601 - val_loss: 1.2345 - val_accuracy: 0.9630\n",
            "Epoch 7/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.9886 - accuracy: 0.9630 - val_loss: 0.6158 - val_accuracy: 0.9770\n",
            "Epoch 8/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.9357 - accuracy: 0.9617 - val_loss: 0.5899 - val_accuracy: 0.9770\n",
            "Epoch 9/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.8998 - accuracy: 0.9651 - val_loss: 0.5207 - val_accuracy: 0.9820\n",
            "Epoch 10/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.8590 - accuracy: 0.9681 - val_loss: 0.6584 - val_accuracy: 0.9770\n",
            "Epoch 11/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.9935 - accuracy: 0.9667 - val_loss: 0.7461 - val_accuracy: 0.9760\n",
            "Epoch 12/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.9255 - accuracy: 0.9673 - val_loss: 0.5812 - val_accuracy: 0.9810\n",
            "Epoch 13/50\n",
            "350/350 [==============================] - 16s 44ms/step - loss: 0.9272 - accuracy: 0.9684 - val_loss: 0.5225 - val_accuracy: 0.9800\n",
            "Epoch 14/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.9231 - accuracy: 0.9669 - val_loss: 1.8828 - val_accuracy: 0.9580\n",
            "Epoch 15/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.9338 - accuracy: 0.9716 - val_loss: 0.7268 - val_accuracy: 0.9820\n",
            "Epoch 16/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 1.0958 - accuracy: 0.9669 - val_loss: 0.7293 - val_accuracy: 0.9780\n",
            "Epoch 17/50\n",
            "350/350 [==============================] - 14s 39ms/step - loss: 0.8791 - accuracy: 0.9693 - val_loss: 0.9605 - val_accuracy: 0.9780\n",
            "Epoch 18/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.0612 - accuracy: 0.9684 - val_loss: 1.0567 - val_accuracy: 0.9820\n",
            "Epoch 19/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.9379 - accuracy: 0.9710 - val_loss: 1.0822 - val_accuracy: 0.9760\n",
            "Epoch 20/50\n",
            "350/350 [==============================] - 15s 41ms/step - loss: 1.0591 - accuracy: 0.9720 - val_loss: 1.2005 - val_accuracy: 0.9760\n",
            "Epoch 21/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 1.0241 - accuracy: 0.9710 - val_loss: 1.2710 - val_accuracy: 0.9750\n",
            "Epoch 22/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.9846 - accuracy: 0.9737 - val_loss: 1.2581 - val_accuracy: 0.9790\n",
            "Epoch 23/50\n",
            "350/350 [==============================] - 14s 41ms/step - loss: 0.8723 - accuracy: 0.9771 - val_loss: 1.4552 - val_accuracy: 0.9730\n",
            "Epoch 24/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.9727 - accuracy: 0.9731 - val_loss: 1.1223 - val_accuracy: 0.9820\n",
            "Epoch 25/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.8847 - accuracy: 0.9757 - val_loss: 1.3401 - val_accuracy: 0.9780\n",
            "Epoch 26/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.9757 - accuracy: 0.9766 - val_loss: 1.6161 - val_accuracy: 0.9740\n",
            "Epoch 27/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.8892 - accuracy: 0.9779 - val_loss: 2.4339 - val_accuracy: 0.9690\n",
            "Epoch 28/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 1.0031 - accuracy: 0.9783 - val_loss: 1.4541 - val_accuracy: 0.9770\n",
            "Epoch 29/50\n",
            "350/350 [==============================] - 14s 38ms/step - loss: 0.9914 - accuracy: 0.9767 - val_loss: 1.2904 - val_accuracy: 0.9810\n",
            "Epoch 30/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.0799 - accuracy: 0.9764 - val_loss: 1.7284 - val_accuracy: 0.9760\n",
            "Epoch 31/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.9420 - accuracy: 0.9747 - val_loss: 1.4169 - val_accuracy: 0.9740\n",
            "Epoch 32/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 1.0437 - accuracy: 0.9771 - val_loss: 1.3847 - val_accuracy: 0.9770\n",
            "Epoch 33/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.0318 - accuracy: 0.9747 - val_loss: 1.1771 - val_accuracy: 0.9790\n",
            "Epoch 34/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 1.0119 - accuracy: 0.9763 - val_loss: 1.4704 - val_accuracy: 0.9770\n",
            "Epoch 35/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.9403 - accuracy: 0.9774 - val_loss: 1.4583 - val_accuracy: 0.9770\n",
            "Epoch 36/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 1.0661 - accuracy: 0.9763 - val_loss: 1.6394 - val_accuracy: 0.9780\n",
            "Epoch 37/50\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 1.0751 - accuracy: 0.9756 - val_loss: 1.7440 - val_accuracy: 0.9730\n",
            "Epoch 38/50\n",
            "350/350 [==============================] - 14s 39ms/step - loss: 1.0919 - accuracy: 0.9741 - val_loss: 1.6738 - val_accuracy: 0.9780\n",
            "Epoch 39/50\n",
            "350/350 [==============================] - 14s 39ms/step - loss: 1.1186 - accuracy: 0.9759 - val_loss: 1.5246 - val_accuracy: 0.9720\n",
            "Epoch 40/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.9576 - accuracy: 0.9781 - val_loss: 1.6128 - val_accuracy: 0.9750\n",
            "Epoch 41/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.9916 - accuracy: 0.9790 - val_loss: 1.7205 - val_accuracy: 0.9770\n",
            "Epoch 42/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.1394 - accuracy: 0.9766 - val_loss: 1.1081 - val_accuracy: 0.9790\n",
            "Epoch 43/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.1284 - accuracy: 0.9773 - val_loss: 1.4044 - val_accuracy: 0.9780\n",
            "Epoch 44/50\n",
            "350/350 [==============================] - 14s 41ms/step - loss: 1.0400 - accuracy: 0.9789 - val_loss: 1.1778 - val_accuracy: 0.9800\n",
            "Epoch 45/50\n",
            "350/350 [==============================] - 14s 38ms/step - loss: 1.1785 - accuracy: 0.9747 - val_loss: 1.9057 - val_accuracy: 0.9770\n",
            "Epoch 46/50\n",
            "350/350 [==============================] - 14s 39ms/step - loss: 0.9859 - accuracy: 0.9797 - val_loss: 2.0763 - val_accuracy: 0.9710\n",
            "Epoch 47/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.0499 - accuracy: 0.9787 - val_loss: 1.6083 - val_accuracy: 0.9780\n",
            "Epoch 48/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.9170 - accuracy: 0.9774 - val_loss: 2.2956 - val_accuracy: 0.9710\n",
            "Epoch 49/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.0984 - accuracy: 0.9779 - val_loss: 1.6031 - val_accuracy: 0.9800\n",
            "Epoch 50/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.8798 - accuracy: 0.9810 - val_loss: 1.0000 - val_accuracy: 0.9810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\n",
        "    \"feature_extraction_with_data_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QrE_tv8qGT3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503746fe-3de3-4856-9775-2f65fc0589f9"
      },
      "id": "QrE_tv8qGT3n",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 3s 41ms/step - loss: 0.1707 - accuracy: 0.9920\n",
            "Test accuracy: 0.992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_PretrainedIncreasedSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)"
      ],
      "metadata": {
        "id": "f3V61Mo3Gyhd"
      },
      "id": "f3V61Mo3Gyhd",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))\n",
        "# conv_base.trainable = False"
      ],
      "metadata": {
        "id": "mBtuPJEaGzyS"
      },
      "id": "mBtuPJEaGzyS",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "make_subset(\"train\", start_index=0, end_index=1500)\n",
        "make_subset(\"validation\", start_index=1500, end_index=2000)\n",
        "make_subset(\"test\", start_index=2000, end_index=3000)\n",
        "\n",
        "# Building the model\n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Running the callback function to monitor validation loss\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)\n"
      ],
      "metadata": {
        "id": "ocOF_TntG3Z3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e063e19-ab42-46a4-e8f4-19fa9cdfd2d4"
      },
      "id": "ocOF_TntG3Z3",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 10.2318 - accuracy: 0.9500 - val_loss: 5.1863 - val_accuracy: 0.9640\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 3.8654 - accuracy: 0.9776 - val_loss: 5.2322 - val_accuracy: 0.9740\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 2.1118 - accuracy: 0.9844 - val_loss: 3.9649 - val_accuracy: 0.9780\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.2344 - accuracy: 0.9911 - val_loss: 5.1407 - val_accuracy: 0.9720\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1501 - accuracy: 0.9909 - val_loss: 4.7105 - val_accuracy: 0.9720\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.9931 - val_loss: 4.8915 - val_accuracy: 0.9760\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5698 - accuracy: 0.9949 - val_loss: 4.5515 - val_accuracy: 0.9760\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6653 - accuracy: 0.9950 - val_loss: 4.8847 - val_accuracy: 0.9770\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3420 - accuracy: 0.9969 - val_loss: 4.9393 - val_accuracy: 0.9760\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.3196 - accuracy: 0.9956 - val_loss: 4.5141 - val_accuracy: 0.9810\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.3549 - accuracy: 0.9974 - val_loss: 4.3383 - val_accuracy: 0.9800\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1546 - accuracy: 0.9980 - val_loss: 4.4961 - val_accuracy: 0.9770\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1282 - accuracy: 0.9984 - val_loss: 4.5531 - val_accuracy: 0.9790\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2634 - accuracy: 0.9977 - val_loss: 4.9843 - val_accuracy: 0.9770\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0841 - accuracy: 0.9989 - val_loss: 5.3878 - val_accuracy: 0.9780\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1530 - accuracy: 0.9981 - val_loss: 5.2731 - val_accuracy: 0.9780\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.1053 - accuracy: 0.9983 - val_loss: 4.9478 - val_accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0665 - accuracy: 0.9993 - val_loss: 5.6564 - val_accuracy: 0.9770\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.2437 - accuracy: 0.9981 - val_loss: 5.5112 - val_accuracy: 0.9780\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.1822 - accuracy: 0.9984 - val_loss: 5.1909 - val_accuracy: 0.9760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "fYQjO4pIG9M4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f405d509-cddb-466c-c34e-e02d417ba3d5"
      },
      "id": "fYQjO4pIG9M4",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9970\n",
            "Test accuracy: 0.997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_PretrainedoptimalSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)"
      ],
      "metadata": {
        "id": "P40KrS5NHB_T"
      },
      "id": "P40KrS5NHB_T",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "conv_base.trainable = False"
      ],
      "metadata": {
        "id": "0a-JHvU9HIbO"
      },
      "id": "0a-JHvU9HIbO",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "iHY8wVWmHLci"
      },
      "id": "iHY8wVWmHLci",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Train the model with varying training sample sizes\n",
        "sample_sizes = [2500,3000,4000,5000]\n",
        "history_dict = []\n",
        "for size in sample_sizes:\n",
        "    # Set up the training subset\n",
        "    make_subset(\"temp_train\", start_index=0, end_index=size)\n",
        "    make_subset(\"validation\", start_index=size, end_index=size+500)\n",
        "    make_subset(\"test\", start_index=size+500, end_index=size+1500)\n",
        "    train_dataset = image_dataset_from_directory(\n",
        "      new_base_dir / \"temp_train\",\n",
        "      image_size=(180, 180),\n",
        "      batch_size=20)\n",
        "    # Running the callback function to monitor validation loss\n",
        "    callbacks = [\n",
        "      keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")]\n",
        "\n",
        "    # Training the model\n",
        "    history = model.fit(\n",
        "      train_features, train_labels,\n",
        "      epochs=20,\n",
        "      validation_data=(val_features, val_labels),\n",
        "      callbacks=callbacks)\n",
        "\n",
        "   # Testing the model\n",
        "    test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "    test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "    print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "GHwBmfnlHMf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a32e4f3-f086-473c-81a0-f43017faa679"
      },
      "id": "GHwBmfnlHMf9",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 10.3330 - accuracy: 0.9490 - val_loss: 5.0387 - val_accuracy: 0.9700\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 4.0844 - accuracy: 0.9763 - val_loss: 4.5030 - val_accuracy: 0.9760\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.9802 - accuracy: 0.9861 - val_loss: 6.9596 - val_accuracy: 0.9670\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.4380 - accuracy: 0.9890 - val_loss: 7.7637 - val_accuracy: 0.9640\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8382 - accuracy: 0.9920 - val_loss: 4.7463 - val_accuracy: 0.9750\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9755 - accuracy: 0.9916 - val_loss: 4.5964 - val_accuracy: 0.9770\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.6727 - accuracy: 0.9939 - val_loss: 4.1239 - val_accuracy: 0.9780\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.6345 - accuracy: 0.9949 - val_loss: 4.0141 - val_accuracy: 0.9780\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.2490 - accuracy: 0.9987 - val_loss: 4.4717 - val_accuracy: 0.9760\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.1347 - accuracy: 0.9979 - val_loss: 4.3540 - val_accuracy: 0.9770\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.2566 - accuracy: 0.9974 - val_loss: 10.6450 - val_accuracy: 0.9620\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.3822 - accuracy: 0.9964 - val_loss: 5.0755 - val_accuracy: 0.9790\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1400 - accuracy: 0.9976 - val_loss: 4.6533 - val_accuracy: 0.9770\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1503 - accuracy: 0.9981 - val_loss: 4.9173 - val_accuracy: 0.9770\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1303 - accuracy: 0.9986 - val_loss: 4.4756 - val_accuracy: 0.9790\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9987 - val_loss: 5.4740 - val_accuracy: 0.9770\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1297 - accuracy: 0.9994 - val_loss: 4.4434 - val_accuracy: 0.9820\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1855 - accuracy: 0.9989 - val_loss: 4.3992 - val_accuracy: 0.9800\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1314 - accuracy: 0.9989 - val_loss: 4.1232 - val_accuracy: 0.9780\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0867 - accuracy: 0.9989 - val_loss: 4.1354 - val_accuracy: 0.9810\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.9980\n",
            "Test accuracy: 0.998\n",
            "Found 6000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.1069 - accuracy: 0.9991 - val_loss: 4.6042 - val_accuracy: 0.9800\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9989 - val_loss: 4.2375 - val_accuracy: 0.9800\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0324 - accuracy: 0.9996 - val_loss: 4.4270 - val_accuracy: 0.9800\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0530 - accuracy: 0.9994 - val_loss: 3.9580 - val_accuracy: 0.9810\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.2043 - accuracy: 0.9986 - val_loss: 4.1184 - val_accuracy: 0.9800\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0542 - accuracy: 0.9993 - val_loss: 5.3360 - val_accuracy: 0.9760\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.0700 - accuracy: 0.9989 - val_loss: 7.2936 - val_accuracy: 0.9720\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0817 - accuracy: 0.9991 - val_loss: 4.8435 - val_accuracy: 0.9790\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1014 - accuracy: 0.9983 - val_loss: 5.6392 - val_accuracy: 0.9770\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0542 - accuracy: 0.9994 - val_loss: 4.9285 - val_accuracy: 0.9810\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0331 - accuracy: 0.9994 - val_loss: 4.6982 - val_accuracy: 0.9800\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0787 - accuracy: 0.9994 - val_loss: 4.5457 - val_accuracy: 0.9830\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0220 - accuracy: 0.9996 - val_loss: 5.5197 - val_accuracy: 0.9740\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0477 - accuracy: 0.9994 - val_loss: 4.7768 - val_accuracy: 0.9810\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.0391 - accuracy: 0.9994 - val_loss: 5.1321 - val_accuracy: 0.9790\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 5.6580 - val_accuracy: 0.9770\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.7170e-10 - accuracy: 1.0000 - val_loss: 5.6526 - val_accuracy: 0.9770\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0220 - accuracy: 0.9997 - val_loss: 4.7671 - val_accuracy: 0.9800\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0558 - accuracy: 0.9993 - val_loss: 6.8535 - val_accuracy: 0.9740\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0267 - accuracy: 0.9999 - val_loss: 4.6645 - val_accuracy: 0.9800\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test accuracy: 1.000\n",
            "Found 8000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0257 - accuracy: 0.9997 - val_loss: 4.9140 - val_accuracy: 0.9780\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9996 - val_loss: 6.0788 - val_accuracy: 0.9800\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9999 - val_loss: 5.4068 - val_accuracy: 0.9780\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0227 - accuracy: 0.9997 - val_loss: 5.1700 - val_accuracy: 0.9780\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 2.5026e-18 - accuracy: 1.0000 - val_loss: 5.1700 - val_accuracy: 0.9780\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9997 - val_loss: 5.3677 - val_accuracy: 0.9800\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 5.1148 - val_accuracy: 0.9790\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 5.0186 - val_accuracy: 0.9770\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.8266e-21 - accuracy: 1.0000 - val_loss: 5.0186 - val_accuracy: 0.9770\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0149 - accuracy: 0.9994 - val_loss: 6.3790 - val_accuracy: 0.9760\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0101 - accuracy: 0.9997 - val_loss: 4.5839 - val_accuracy: 0.9790\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 7.3521e-21 - accuracy: 1.0000 - val_loss: 4.5839 - val_accuracy: 0.9790\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0361 - accuracy: 0.9997 - val_loss: 4.5751 - val_accuracy: 0.9780\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9999 - val_loss: 6.0783 - val_accuracy: 0.9780\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0189 - accuracy: 0.9999 - val_loss: 5.1922 - val_accuracy: 0.9790\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.6890e-06 - accuracy: 1.0000 - val_loss: 6.3694 - val_accuracy: 0.9760\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9999 - val_loss: 5.1133 - val_accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9997 - val_loss: 5.4546 - val_accuracy: 0.9760\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 5.6654e-08 - accuracy: 1.0000 - val_loss: 5.2347 - val_accuracy: 0.9800\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.5600e-33 - accuracy: 1.0000 - val_loss: 5.2347 - val_accuracy: 0.9800\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test accuracy: 1.000\n",
            "Found 10000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0264 - accuracy: 0.9997 - val_loss: 5.1691 - val_accuracy: 0.9790\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 3.0459e-21 - accuracy: 1.0000 - val_loss: 5.1691 - val_accuracy: 0.9790\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1415e-30 - accuracy: 1.0000 - val_loss: 5.1691 - val_accuracy: 0.9790\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 4.2283e-09 - accuracy: 1.0000 - val_loss: 5.1412 - val_accuracy: 0.9810\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 9.2432e-21 - accuracy: 1.0000 - val_loss: 5.1412 - val_accuracy: 0.9810\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.9472e-34 - accuracy: 1.0000 - val_loss: 5.1412 - val_accuracy: 0.9810\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.0713e-23 - accuracy: 1.0000 - val_loss: 5.1412 - val_accuracy: 0.9810\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.1412 - val_accuracy: 0.9810\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0093 - accuracy: 0.9997 - val_loss: 5.6038 - val_accuracy: 0.9800\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 6.2527 - val_accuracy: 0.9740\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 5.7235 - val_accuracy: 0.9790\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 5.3952 - val_accuracy: 0.9800\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 3.7764e-10 - accuracy: 1.0000 - val_loss: 5.3875 - val_accuracy: 0.9800\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 5.5978 - val_accuracy: 0.9780\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0211 - accuracy: 0.9996 - val_loss: 5.7320 - val_accuracy: 0.9800\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 5.7898e-10 - accuracy: 1.0000 - val_loss: 5.7268 - val_accuracy: 0.9800\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.1455e-35 - accuracy: 1.0000 - val_loss: 5.7268 - val_accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 5.4508e-29 - accuracy: 1.0000 - val_loss: 5.7268 - val_accuracy: 0.9800\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0798e-26 - accuracy: 1.0000 - val_loss: 5.7268 - val_accuracy: 0.9800\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.6152e-23 - accuracy: 1.0000 - val_loss: 5.7268 - val_accuracy: 0.9800\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test accuracy: 1.000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}